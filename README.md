#If you use this dataset please cite our paper 



Link to our paper:
https://arxiv.org/abs/2209.12573




# Dataset
You can download the datasets from the folowing links:

English Dataset:

https://drive.google.com/file/d/1XgO4F39fl17qkcvci0iMglDaUo4-VvDa/view?usp=sharing

Mixed Dataset:

https://drive.google.com/file/d/1x7wxxdRvrBTI5fsjZ8M0BCxe5-_eunnN/view?usp=sharing


here are 2 datasets of audios, the first one is the the English dataset which is all the files expect the arabic_fake and arabic_real
to create the first dataset and use it download all the audios and compine them in a file then use 90% of these audios as a training set (10% of it is validation which the model take without the need to do it manually) while the remaining 10% for testing

the Arbic dataset is by compining the files with the English that you already have to create the mixed dataset and as before 90% is for training (10% of it is validation which the model take without the need to do it manually) and 10% for testing



NOTE:
-to know the real and fake audios during tarining the audios that ends with 'r' are real and the one ands with 'f' are faked.
-The format of all the audios is .WAV
-the duration of the audios is 20 second long
